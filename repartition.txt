ğŸ”· PLAN ORAL â€” DurÃ©e totale : 14min30s Ã  15min
ğŸ¬ 0. Introduction et accroche (1 min)
PrÃ©senter lâ€™Ã©quipe en 10s.

Contexte et problÃ©matique :

"Aujourdâ€™hui, les images sont partout : mÃ©decine, photographie, surveillance... et elles sont souvent bruitÃ©es. Ce bruit peut dÃ©grader la qualitÃ© et rendre lâ€™analyse impossible. Notre projet visait Ã  restaurer ces images automatiquement."

Objectif SMART :

"DÃ©velopper un outil efficace et interactif de dÃ©bruitage dâ€™images par ACP, applicable Ã  diffÃ©rentes mÃ©thodes, patchs, seuils, en moins de 3 secondes par image 512x512, pour produire une image la plus fidÃ¨le possible."

ğŸ§  1. ThÃ©orie et approche mathÃ©matique (2 min)
Expliquer trÃ¨s simplement ce quâ€™est lâ€™ACP (sans rentrer dans les Ã©quations).

Montrer visuellement (sur slide ou schÃ©ma) la projection â†’ seuillage â†’ reconstruction.

Expliquer le rÃ´le des patchs et du seuillage Visu/Bayes, Dur/Soft.

Glisser une phrase sur le lien avec les bases orthonormÃ©es et projections.

â†’ Coche CritÃ¨re 6a, 1d, 7a.

ğŸ’» 2. Architecture logicielle (2 min)
Diagramme de classes (1 slide max) : expliquer les grandes classes :

"ImageUtils pour la gestion dâ€™image, Thresholding pour le seuillage, ACP pour lâ€™analyse math, et une interface JavaFX intuitive."

Mentionner la division Global vs Local et les diffÃ©rences.

Citer la gestion des fichiers, le bruitage, et lâ€™export automatique des rÃ©sultats.

â†’ Coche CritÃ¨re 6b, 2, 3b, 5.

âš™ï¸ 3. FonctionnalitÃ©s & IHM (2 min)
DÃ©monstration vidÃ©o (2 min maximum, fluide, prÃ©parÃ©e Ã  lâ€™avance).

Bruitage d'une image, rÃ©glage des paramÃ¨tres (sigma, patchs, mÃ©thode), puis comparaison des rÃ©sultats.

Expliquer les Ã©lÃ©ments clÃ©s de lâ€™IHM :

sliders pour patchs et bruit

menu dÃ©roulant pour les mÃ©thodes

boutons bruitage / dÃ©bruitage / optimal

affichage MSE / PSNR

â†’ Coche CritÃ¨re 4, 5, 10d.

ğŸ“Š 4. RÃ©sultats et interprÃ©tation (3 min)
3 tableaux synthÃ©tiques (tirÃ©s du rapport) :

Meilleur patch = 8x8

Meilleur mÃ©thode = Local + VisuShrink + Dur

Temps dâ€™exÃ©cution selon la taille

InterprÃ©ter :

"On observe une amÃ©lioration de 80% en MSE, et un PSNR de presque 29 dB, ce qui correspond Ã  une trÃ¨s bonne qualitÃ© visuelle."

Mentionner les rÃ©sultats mauvais avec Bayes + Dur â†’ justifier.

â†’ Coche CritÃ¨res 8e, 8f, 8g.

ğŸ“‰ 5. Limites, bugs et itÃ©rations (2 min)
Expliquer :

ProblÃ¨me du trait vertical avec patch pair (rÃ©solu)

Limites sur grandes images (temps)

ProblÃ¨me dâ€™estimation de Ïƒ_signal (Bayes)

Propositions dâ€™amÃ©lioration :

Fusion local/global

Deep learning avec estimation automatique du bruit

â†’ Coche CritÃ¨res 10, 7b.

ğŸ§‘â€ğŸ¤â€ğŸ§‘ 6. Travail collaboratif (1 min)
Organisation : GitHub + 15 min de rÃ©u tous les 2 jours.

RÃ©partition des tÃ¢ches Ã©quilibrÃ©e (IHM, maths, code, rapport).

Bonne coordination malgrÃ© les spÃ©cialitÃ©s diffÃ©rentes.

â†’ Coche CritÃ¨re 9.

ğŸ¯ 7. Conclusion (1 min)
RÃ©sumÃ© : projet complet, code propre, rÃ©sultats solides.

Fonctionne sur toute image, 4 mÃ©thodes Ã— 2 seuils = 8 rÃ©sultats.

Impact : trÃ¨s utile pour des cas rÃ©els (mÃ©decine, imagerie satellite).

Phrase finale :

"Ce projet nous a appris Ã  coder proprement, Ã  travailler en Ã©quipe, et surtout Ã  rendre des mÃ©thodes mathÃ©matiques puissantes accessibles et utiles."

â†’ Coche CritÃ¨re 1c, 5.1.
